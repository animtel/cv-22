{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5fe776-f7e6-48ab-a878-af847627d7b5",
   "metadata": {},
   "source": [
    "Video was given from https://motchallenge.net/vis/MOT16-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a9493f2-6b26-4161-b921-a82670144e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install distinctipy==1.2.2 filterpy==1.4.5 lap==0.4.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745a0206-1faf-4b40-8934-6a4d8eee0be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd536e932e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sort import Sort\n",
    "import distinctipy\n",
    "\n",
    "sample_img = np.random.rand(3,3,3)\n",
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc5f5c7-9591-4d28-b7e1-4e12be83c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f874332-432f-41ec-86ae-d4c23d416c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-12-22 Python-3.8.12 torch-1.11.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True).to(device)\n",
    "model.float()\n",
    "model.eval()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a938651b-dc1a-4ee2-bcdd-0a966b31f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('data')\n",
    "\n",
    "reference_vid = data_dir / 'ref_vid.mp4'\n",
    "\n",
    "save_to = data_dir / 'hungurian_baseline_results' / reference_vid.stem\n",
    "save_to.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f057ab-8061-4c51-a8e4-c9ea065a66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_tracker = Sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2ef142e-bd0c-4ca6-b945-6ced898d3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf /app/notebooks/object_tracking/data/hungurian_baseline_results/ref_vid/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f33d10e-476e-4356-a206-d1beb19c97e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.01501), tensor(0.91636))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou = torch.rand(5,6)\n",
    "iou.min(), iou.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab3eb406-7ba2-470b-a6d9-bcd655bdeaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.79100, 0.07926, 0.43298, 0.58862, 0.23955, 0.26699],\n",
       "        [0.86151, 0.74992, 0.15727, 0.59859, 0.77498, 0.15379],\n",
       "        [0.87713, 0.41904, 0.83314, 0.37887, 0.77767, 0.16067],\n",
       "        [0.33383, 0.80378, 0.08917, 0.15110, 0.01501, 0.26593],\n",
       "        [0.02479, 0.55631, 0.91636, 0.57197, 0.03458, 0.60029]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d6611b8-f976-4d18-881b-bdb0c60ae0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.ops import box_iou\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def hungarian_match(bboxs1, bboxs2, min_iou = 0.3):\n",
    "    \"\"\"\n",
    "    bboxs1: m x 4\n",
    "    bboxs2: n x 4\n",
    "    returns: m x 1\n",
    "    \"\"\"\n",
    "    ious = box_iou(bboxs1,bboxs2).cpu().numpy()\n",
    "    row_ind, col_ind = linear_sum_assignment(-ious)\n",
    "    \n",
    "    new_row_ind, new_col_ind = [], []\n",
    "    \n",
    "    for m in zip(row_ind, col_ind):\n",
    "        if(ious[m[0], m[1]]>=min_iou):\n",
    "            new_row_ind.append(m[0])\n",
    "            new_col_ind.append(m[1])\n",
    "    \n",
    "    return np.array(new_row_ind), np.array(new_col_ind)\n",
    "\n",
    "def color_t(idx):\n",
    "    state = np.random.get_state()\n",
    "    numpy.random.seed(seed=idx)\n",
    "    val = (np.random.randint(256), np.random.randint(256), np.random.randint(256))\n",
    "    np.random.set_state(state)\n",
    "    return val\n",
    "\n",
    "def update_trackers(trackers, detections, max_idx):\n",
    "    \"\"\"\n",
    "    trackers - objects that we currently tracking\n",
    "    detections - not yet classified bboxes that detected on new frame\n",
    "    \n",
    "    From detections we want to understand few things:\n",
    "    1. Who is new to trackers?\n",
    "    2. Who is lost from trackers?\n",
    "    \"\"\"\n",
    "    if len(trackers) == 0: \n",
    "        trks_inds = torch.arange(len(detections)).unsqueeze(-1).to(device)\n",
    "        return torch.cat([detections, trks_inds], dim=-1), 0\n",
    "    \n",
    "    max_id = trackers[..., 4].max().item()\n",
    "    \n",
    "    max_id = max(max_id, max_idx)\n",
    "    \n",
    "    row_ind, col_ind = hungarian_match(trackers[..., :4], detections)\n",
    "    \n",
    "    new_detection_ind = set(range(len(detections))) - set(col_ind) \n",
    "    \n",
    "    tracked_ind = set(row_ind)\n",
    "    \n",
    "    trackers[list(row_ind), :4] = detections[list(col_ind)]\n",
    "    trackers = trackers[list(tracked_ind)]\n",
    "    \n",
    "    new_detected = detections[list(new_detection_ind)]\n",
    "    new_trackers_inds = torch.arange(max_id+1, max_id+len(new_detected)+1).unsqueeze(-1).to(device)\n",
    "    new_trackers = torch.cat([new_detected,new_trackers_inds], dim=-1)\n",
    "    \n",
    "    trackers = torch.cat([trackers, new_trackers], dim=0)\n",
    "    \n",
    "    return trackers, max_id+len(new_detected)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5bca1e58-7abb-44c1-82df-f32c9b961d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                            | 271/1050 [03:22<09:43,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "file = str(reference_vid)\n",
    "verbose = True\n",
    "\n",
    "capture = cv2.VideoCapture(file)\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "n_frames = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "bbs_ids_frame_count = {}\n",
    "\n",
    "frames = []\n",
    "\n",
    "track_bbs_ids = []\n",
    "max_trackers_id = 0\n",
    "\n",
    "pb = np.arange(n_frames)\n",
    "if verbose:\n",
    "    pb = tqdm(pb)\n",
    "\n",
    "for i in pb:\n",
    "    success, image_cv = capture.read()\n",
    "    if i > 270: break # TODO: remove this line\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    preds = model(image_cv)\n",
    "    detections = preds.pred[0][..., :4]\n",
    "    track_bbs_ids, max_trackers_id = update_trackers(track_bbs_ids, detections, max_trackers_id)\n",
    "    \n",
    "    for j in range(len(track_bbs_ids)):\n",
    "        coords = track_bbs_ids[j]\n",
    "        x1, y1, x2, y2 = int(coords[0]), int(coords[1]), int(coords[2]), int(coords[3])\n",
    "        \n",
    "        name_idx = int(coords[4])\n",
    "        \n",
    "        if name_idx in bbs_ids_frame_count.keys():\n",
    "            bbs_ids_frame_count[name_idx] += 1\n",
    "        else:\n",
    "            bbs_ids_frame_count[name_idx] = 1\n",
    "            \n",
    "        sec_per_id = bbs_ids_frame_count[name_idx] / fps\n",
    "            \n",
    "        name = f\"ID:{name_idx}|T:{sec_per_id:.2f}s\"\n",
    "        color = color_t(name_idx)\n",
    "        \n",
    "        cv2.rectangle(image_cv, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image_cv, name, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        cv2.imwrite(str(save_to / f\"{int(i)}.png\"), image_cv)\n",
    "        # plt.imshow(image_cv)\n",
    "        # plt.show()\n",
    "        \n",
    "    # if i % frame_read_freq == 0:\n",
    "    #     frame = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)\n",
    "    #     frame = torch.tensor(frame/255, dtype=torch.float32)\n",
    "    #     frames.append(frame.permute(2,0,1)[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e3ed8-fc29-4b17-95dc-8a666dcdc4d3",
   "metadata": {},
   "source": [
    "# Save video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "438ab9e0-4783-44c1-8c3e-1769ef4689df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in /opt/conda/lib/python3.8/site-packages (1.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install moviepy --upgrade\n",
    "!pip install ffmpeg --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "550bb5c7-aa16-4a90-8e7e-181f75bed231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271/271 [00:04<00:00, 62.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = str(save_to)\n",
    "video_name = 'video_hungarian.mp4'\n",
    "fps = 30\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "sorted_img_ids = sorted([int(i.split('.')[0]) for i in images])\n",
    "images = [f\"{i}.png\" for i in sorted_img_ids]\n",
    "\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "video = cv2.VideoWriter(video_name, fourcc, fps, (width,height))\n",
    "\n",
    "for image in tqdm(images):\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd6448-b5c5-4a72-a502-96e0ebf05367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54b019-3003-4624-8359-364d9d076dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797dab90-3c2a-4933-b5f3-cd3c628bad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e7d51-b007-4ff6-9874-382c98d7dbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f5661-b15a-432b-b9c2-7b4b3f18eda8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
