{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5fe776-f7e6-48ab-a878-af847627d7b5",
   "metadata": {},
   "source": [
    "Video was given from https://motchallenge.net/vis/MOT16-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a9493f2-6b26-4161-b921-a82670144e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install distinctipy==1.2.2 filterpy==1.4.5 lap==0.4.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745a0206-1faf-4b40-8934-6a4d8eee0be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f88ce5c72e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sort import Sort\n",
    "import distinctipy\n",
    "\n",
    "sample_img = np.random.rand(3,3,3)\n",
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc5f5c7-9591-4d28-b7e1-4e12be83c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f874332-432f-41ec-86ae-d4c23d416c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2022-12-22 Python-3.8.12 torch-1.11.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True).to(device)\n",
    "model.float()\n",
    "model.eval()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a938651b-dc1a-4ee2-bcdd-0a966b31f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('data')\n",
    "\n",
    "reference_vid = data_dir / 'ref_vid.mp4'\n",
    "\n",
    "save_to = data_dir / 'custom_sort_results' / reference_vid.stem\n",
    "save_to.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f057ab-8061-4c51-a8e4-c9ea065a66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_tracker = Sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2ef142e-bd0c-4ca6-b945-6ced898d3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf /app/notebooks/object_tracking/data/custom_sort_results/ref_vid/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6611b8-f976-4d18-881b-bdb0c60ae0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.ops import box_iou\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def hungarian_match(bboxs1, bboxs2, min_iou = 0.3):\n",
    "    \"\"\"\n",
    "    bboxs1: m x 4\n",
    "    bboxs2: n x 4\n",
    "    returns: m x 1\n",
    "    \"\"\"\n",
    "    ious = box_iou(bboxs1,bboxs2).cpu().numpy()\n",
    "    row_ind, col_ind = linear_sum_assignment(-ious)\n",
    "    \n",
    "    new_row_ind, new_col_ind = [], []\n",
    "    \n",
    "    for m in zip(row_ind, col_ind):\n",
    "        if(ious[m[0], m[1]]>=min_iou):\n",
    "            new_row_ind.append(m[0])\n",
    "            new_col_ind.append(m[1])\n",
    "    \n",
    "    return np.array(new_row_ind), np.array(new_col_ind)\n",
    "\n",
    "def color_t(idx):\n",
    "    state = np.random.get_state()\n",
    "    numpy.random.seed(seed=idx)\n",
    "    val = (np.random.randint(256), np.random.randint(256), np.random.randint(256))\n",
    "    np.random.set_state(state)\n",
    "    return val\n",
    "\n",
    "def update_trackers(trackers, detections, max_idx):\n",
    "    \"\"\"\n",
    "    trackers - objects that we currently tracking\n",
    "    detections - not yet classified bboxes that detected on new frame\n",
    "    \n",
    "    From detections we want to understand few things:\n",
    "    1. Who is new to trackers?\n",
    "    2. Who is lost from trackers?\n",
    "    \"\"\"\n",
    "    if len(trackers) == 0: \n",
    "        trks_inds = torch.arange(len(detections)).unsqueeze(-1).to(device)\n",
    "        return torch.cat([detections, trks_inds], dim=-1), len(detections)+1\n",
    "    \n",
    "    max_id = trackers[..., 4].max().item()\n",
    "    \n",
    "    max_id = max(max_id, max_idx)\n",
    "    \n",
    "    row_ind, col_ind = hungarian_match(trackers[..., :4], detections)\n",
    "    \n",
    "    new_detection_ind = set(range(len(detections))) - set(col_ind) \n",
    "    \n",
    "    tracked_ind = set(row_ind)\n",
    "    \n",
    "    trackers[list(row_ind), :4] = detections[list(col_ind)]\n",
    "    trackers = trackers[list(tracked_ind)]\n",
    "    \n",
    "    new_detected = detections[list(new_detection_ind)]\n",
    "    new_trackers_inds = torch.arange(max_id+1, max_id+len(new_detected)+1).unsqueeze(-1).to(device)\n",
    "    new_trackers = torch.cat([new_detected,new_trackers_inds], dim=-1)\n",
    "    \n",
    "    trackers = torch.cat([trackers, new_trackers], dim=0)\n",
    "    \n",
    "    return trackers, max_id+len(new_detected)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6025b7a1-4aa0-40af-970f-ca325a864422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from numpy.random import randn\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    center_x = (x1 + x2) / 2\n",
    "    center_y = (y1 + y2) / 2\n",
    "    scale = (x2 - x1) * (y2 - y1)\n",
    "    aspect_ratio = (x2 - x1) / (y2 - y1)\n",
    "\n",
    "    return np.array([center_x, center_y, scale, aspect_ratio]).reshape((4, 1))\n",
    "\n",
    "def convert_x_to_bbox(z):\n",
    "    center_x, center_y, scale, aspect_ratio = z\n",
    "    width = math.sqrt(scale * aspect_ratio)\n",
    "    height = math.sqrt(scale / aspect_ratio)\n",
    "    x1 = center_x - width / 2\n",
    "    y1 = center_y - height / 2\n",
    "    x2 = center_x + width / 2\n",
    "    y2 = center_y + height / 2\n",
    "\n",
    "    return np.array([x1, y1, x2, y2]).reshape((1,4))\n",
    "\n",
    "class KalmanBoxTracker(object):\n",
    "    def __init__(self,bbox):\n",
    "        self.idx = bbox[4]\n",
    "        bbox = bbox[:4]\n",
    "        \n",
    "        #define constant velocity model\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "        self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "        self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "        self.kf.R[2:,2:] *= 10.\n",
    "        self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "        self.kf.P *= 10.\n",
    "        self.kf.Q[-1,-1] *= 0.01\n",
    "        self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "        self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "\n",
    "    def update(self,bbox):\n",
    "        self.kf.update(convert_bbox_to_z(bbox[:4]))\n",
    "\n",
    "    def predict(self):\n",
    "        self.kf.predict()\n",
    "        return convert_x_to_bbox(self.kf.x[:4])\n",
    "\n",
    "    def get_state(self):\n",
    "        return convert_x_to_bbox(self.kf.x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f06fab77-676f-44dc-b7ff-fca4ccfa393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustSORT:\n",
    "    def __init__(self):\n",
    "        self.trackers = []\n",
    "        self.max_trackers_id = 0\n",
    "        \n",
    "    def update(self, detections):\n",
    "        if self.trackers == []:\n",
    "            track_bbs_ids, self.max_trackers_id = update_trackers([], detections, self.max_trackers_id)\n",
    "            track_bbs_ids = track_bbs_ids.cpu().numpy()\n",
    "            for matched_tracker in track_bbs_ids:\n",
    "                self.trackers.append(KalmanBoxTracker(matched_tracker))\n",
    "            return track_bbs_ids\n",
    "        \n",
    "        \n",
    "        bbs_trackers = []\n",
    "        for i in self.trackers:\n",
    "            bbox_coords = i.predict()[0]\n",
    "            bbox_idx = np.array([i.idx])\n",
    "            bbox_arr = np.concatenate([bbox_coords, bbox_idx])\n",
    "            bbs_trackers.append(bbox_arr)\n",
    "        bbs_trackers = torch.tensor(bbs_trackers).to(device).to(torch.float32)\n",
    "        \n",
    "        track_bbs_ids, max_trackers_id = update_trackers(bbs_trackers, detections, self.max_trackers_id)\n",
    "        track_bbs_ids = track_bbs_ids.cpu().numpy()\n",
    "        \n",
    "        new_trackers = []\n",
    "        for tracker in self.trackers:\n",
    "            for matched_tracker in track_bbs_ids:\n",
    "                if matched_tracker[4] == tracker.idx:\n",
    "                    tracker.update(matched_tracker[:4])\n",
    "                    new_trackers.append(tracker)\n",
    "        \n",
    "        # print(\"(track_bbs_ids[:, 4] > self.max_trackers_id).sum(): \", (track_bbs_ids[:, 4] > self.max_trackers_id).sum())\n",
    "        # print(\"track_bbs_ids[:, 4].max(): \", track_bbs_ids[:, 4].max())\n",
    "        counter = 0\n",
    "        for matched_tracker in track_bbs_ids:\n",
    "            if matched_tracker[4] > self.max_trackers_id:\n",
    "                counter += 1\n",
    "                # print(matched_tracker[4], self.max_trackers_id)\n",
    "                new_trackers.append(KalmanBoxTracker(matched_tracker))\n",
    "        \n",
    "        self.max_trackers_id = max_trackers_id\n",
    "                \n",
    "        # print(\"self.max_trackers_id: \", self.max_trackers_id)\n",
    "        # print(\"counter: \", counter)\n",
    "        \n",
    "        self.trackers = new_trackers\n",
    "        \n",
    "        result_bboxes = []\n",
    "        for i in self.trackers:\n",
    "            bbox_coords = i.get_state()[0]\n",
    "            bbox_idx = np.array([i.idx])\n",
    "            bbox_arr = np.concatenate([bbox_coords, bbox_idx])\n",
    "            result_bboxes.append(bbox_arr)\n",
    "        \n",
    "        return np.array(result_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2744e7ca-8d60-437b-a56e-c7b1dfadfb91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1050/1050 [01:39<00:00, 10.60it/s]\n"
     ]
    }
   ],
   "source": [
    "file = str(reference_vid)\n",
    "verbose = True\n",
    "\n",
    "capture = cv2.VideoCapture(file)\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "n_frames = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "bbs_ids_frame_count = {}\n",
    "\n",
    "frames = []\n",
    "\n",
    "sort = CustSORT()\n",
    "\n",
    "pb = np.arange(n_frames)\n",
    "if verbose:\n",
    "    pb = tqdm(pb)\n",
    "    \n",
    "def generate_noise(detections):\n",
    "    noise = (torch.randn(detections.shape) * 50).to(device)\n",
    "    noise[noise < 0] *= -1.\n",
    "    return noise\n",
    "\n",
    "for i in pb:\n",
    "    success, image_cv = capture.read()\n",
    "    # if i > 100: break # TODO: remove this line\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    preds = model(image_cv)\n",
    "    detections = preds.pred[0][..., :4]\n",
    "    detections = detections# + generate_noise(detections)\n",
    "    track_bbs_ids = sort.update(detections)\n",
    "    \n",
    "    for j in range(len(track_bbs_ids)):\n",
    "        coords = track_bbs_ids[j]\n",
    "        x1, y1, x2, y2 = int(coords[0]), int(coords[1]), int(coords[2]), int(coords[3])\n",
    "        \n",
    "        name_idx = int(coords[4])\n",
    "        \n",
    "        if name_idx in bbs_ids_frame_count.keys():\n",
    "            bbs_ids_frame_count[name_idx] += 1\n",
    "        else:\n",
    "            bbs_ids_frame_count[name_idx] = 1\n",
    "            \n",
    "        sec_per_id = bbs_ids_frame_count[name_idx] / fps\n",
    "            \n",
    "        name = f\"ID:{name_idx}|T:{sec_per_id:.2f}s\"\n",
    "        color = color_t(name_idx)\n",
    "        \n",
    "        cv2.rectangle(image_cv, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image_cv, name, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "    \n",
    "    dets_count = f\"N Detections: {len(sort.trackers)}\"\n",
    "    color = (255, 0, 0)\n",
    "\n",
    "    cv2.putText(image_cv, dets_count, (0, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "    \n",
    "    cv2.imwrite(str(save_to / f\"{int(i)}.png\"), image_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f7808-fa45-4817-8c4d-68802f0b2d32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Kalman filter on one bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5bca1e58-7abb-44c1-82df-f32c9b961d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████████████████▏                                                                             | 396/1050 [00:30<00:50, 13.08it/s]\n"
     ]
    }
   ],
   "source": [
    "file = str(reference_vid)\n",
    "verbose = True\n",
    "\n",
    "capture = cv2.VideoCapture(file)\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "n_frames = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "bbs_ids_frame_count = {}\n",
    "\n",
    "frames = []\n",
    "\n",
    "track_bbs_ids = []\n",
    "max_trackers_id = 0\n",
    "\n",
    "pb = np.arange(n_frames)\n",
    "if verbose:\n",
    "    pb = tqdm(pb)\n",
    "    \n",
    "kf = None\n",
    "\n",
    "for i in pb:\n",
    "    success, image_cv = capture.read()\n",
    "    if i > 395: break # TODO: remove this line\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    preds = model(image_cv)\n",
    "    detections = preds.pred[0][..., :4]\n",
    "    track_bbs_ids, max_trackers_id = update_trackers(track_bbs_ids, detections, max_trackers_id)\n",
    "    \n",
    "    raw_coords = track_bbs_ids[track_bbs_ids[:, 4] == 4.][0].cpu().numpy()\n",
    "    \n",
    "    coords = track_bbs_ids[track_bbs_ids[:, 4] == 4.][0].cpu().numpy()\n",
    "    \n",
    "    name_idx = int(coords[4])\n",
    "    \n",
    "    if kf == None:\n",
    "        kf = KalmanBoxTracker(coords)\n",
    "    kf.predict()[0]\n",
    "    \n",
    "    kf.update(coords)\n",
    "    \n",
    "    coords = kf.get_state()[0]\n",
    "    \n",
    "    x1, y1, x2, y2 = int(coords[0]), int(coords[1]), int(coords[2]), int(coords[3])\n",
    "\n",
    "    if name_idx in bbs_ids_frame_count.keys():\n",
    "        bbs_ids_frame_count[name_idx] += 1\n",
    "    else:\n",
    "        bbs_ids_frame_count[name_idx] = 1\n",
    "\n",
    "    sec_per_id = bbs_ids_frame_count[name_idx] / fps\n",
    "\n",
    "    name = f\"ID:{name_idx}|T:{sec_per_id:.2f}s\"\n",
    "    color = color_t(name_idx)\n",
    "    color_raw = color_t(name_idx+1)\n",
    "\n",
    "    cv2.rectangle(image_cv, (int(raw_coords[0]), int(raw_coords[1])), (int(raw_coords[2]), int(raw_coords[3])), color_raw, 2)\n",
    "    cv2.putText(image_cv, name, (int(raw_coords[0]), int(raw_coords[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color_raw, 2)\n",
    "    \n",
    "    cv2.rectangle(image_cv, (x1, y1), (x2, y2), color, 2)\n",
    "    cv2.putText(image_cv, name, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "    \n",
    "    cv2.imwrite(str(save_to / f\"{int(i)}.png\"), image_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cba04d5-9bb1-463d-baf9-0c94ec0916f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521.86285"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06059328-5327-4d31-92fa-9f2fcc365536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     521.86,      64.777,      555.21,      156.76,           4], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf368c71-4d7b-4160-b45b-5ee1f7c145e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([521.86285,  64.77745, 555.20526, 156.76003,   4.00000], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e3ed8-fc29-4b17-95dc-8a666dcdc4d3",
   "metadata": {},
   "source": [
    "# Save video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "438ab9e0-4783-44c1-8c3e-1769ef4689df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in /opt/conda/lib/python3.8/site-packages (1.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install moviepy --upgrade\n",
    "# !pip install ffmpeg --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "550bb5c7-aa16-4a90-8e7e-181f75bed231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1050/1050 [00:16<00:00, 62.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = str(save_to)\n",
    "video_name = 'video_custom_sort.mp4'\n",
    "fps = 30\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "sorted_img_ids = sorted([int(i.split('.')[0]) for i in images])\n",
    "images = [f\"{i}.png\" for i in sorted_img_ids]\n",
    "\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "video = cv2.VideoWriter(video_name, fourcc, fps, (width,height))\n",
    "\n",
    "for image in tqdm(images):\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
