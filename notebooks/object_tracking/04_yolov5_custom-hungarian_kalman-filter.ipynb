{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5fe776-f7e6-48ab-a878-af847627d7b5",
   "metadata": {},
   "source": [
    "Video was given from https://motchallenge.net/vis/MOT16-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a9493f2-6b26-4161-b921-a82670144e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install distinctipy==1.2.2 filterpy==1.4.5 lap==0.4.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "745a0206-1faf-4b40-8934-6a4d8eee0be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0fb31c1c70>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sort import Sort\n",
    "import distinctipy\n",
    "\n",
    "sample_img = np.random.rand(3,3,3)\n",
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7bc5f5c7-9591-4d28-b7e1-4e12be83c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9f874332-432f-41ec-86ae-d4c23d416c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 üöÄ 2022-12-22 Python-3.8.12 torch-1.11.0 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True).to(device)\n",
    "model.float()\n",
    "model.eval()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a938651b-dc1a-4ee2-bcdd-0a966b31f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('data')\n",
    "\n",
    "reference_vid = data_dir / 'ref_vid.mp4'\n",
    "\n",
    "save_to = data_dir / 'hungurian_baseline_results' / reference_vid.stem\n",
    "save_to.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "83f057ab-8061-4c51-a8e4-c9ea065a66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_tracker = Sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f2ef142e-bd0c-4ca6-b945-6ced898d3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf /app/notebooks/object_tracking/data/hungurian_baseline_results/ref_vid/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4d6611b8-f976-4d18-881b-bdb0c60ae0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.ops import box_iou\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def hungarian_match(bboxs1, bboxs2, min_iou = 0.3):\n",
    "    \"\"\"\n",
    "    bboxs1: m x 4\n",
    "    bboxs2: n x 4\n",
    "    returns: m x 1\n",
    "    \"\"\"\n",
    "    ious = box_iou(bboxs1,bboxs2).cpu().numpy()\n",
    "    row_ind, col_ind = linear_sum_assignment(-ious)\n",
    "    \n",
    "    new_row_ind, new_col_ind = [], []\n",
    "    \n",
    "    for m in zip(row_ind, col_ind):\n",
    "        if(ious[m[0], m[1]]>=min_iou):\n",
    "            new_row_ind.append(m[0])\n",
    "            new_col_ind.append(m[1])\n",
    "    \n",
    "    return np.array(new_row_ind), np.array(new_col_ind)\n",
    "\n",
    "def color_t(idx):\n",
    "    state = np.random.get_state()\n",
    "    numpy.random.seed(seed=idx)\n",
    "    val = (np.random.randint(256), np.random.randint(256), np.random.randint(256))\n",
    "    np.random.set_state(state)\n",
    "    return val\n",
    "\n",
    "def update_trackers(trackers, detections, max_idx):\n",
    "    \"\"\"\n",
    "    trackers - objects that we currently tracking\n",
    "    detections - not yet classified bboxes that detected on new frame\n",
    "    \n",
    "    From detections we want to understand few things:\n",
    "    1. Who is new to trackers?\n",
    "    2. Who is lost from trackers?\n",
    "    \"\"\"\n",
    "    if len(trackers) == 0: \n",
    "        trks_inds = torch.arange(len(detections)).unsqueeze(-1).to(device)\n",
    "        return torch.cat([detections, trks_inds], dim=-1), len(detections)+1\n",
    "    \n",
    "    max_id = trackers[..., 4].max().item()\n",
    "    \n",
    "    max_id = max(max_id, max_idx)\n",
    "    \n",
    "    row_ind, col_ind = hungarian_match(trackers[..., :4], detections)\n",
    "    \n",
    "    new_detection_ind = set(range(len(detections))) - set(col_ind) \n",
    "    \n",
    "    tracked_ind = set(row_ind)\n",
    "    \n",
    "    trackers[list(row_ind), :4] = detections[list(col_ind)]\n",
    "    trackers = trackers[list(tracked_ind)]\n",
    "    \n",
    "    new_detected = detections[list(new_detection_ind)]\n",
    "    new_trackers_inds = torch.arange(max_id+1, max_id+len(new_detected)+1).unsqueeze(-1).to(device)\n",
    "    new_trackers = torch.cat([new_detected,new_trackers_inds], dim=-1)\n",
    "    \n",
    "    trackers = torch.cat([trackers, new_trackers], dim=0)\n",
    "    \n",
    "    return trackers, max_id+len(new_detected)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6025b7a1-4aa0-40af-970f-ca325a864422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from numpy.random import randn\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    center_x = (x1 + x2) / 2\n",
    "    center_y = (y1 + y2) / 2\n",
    "    scale = (x2 - x1) * (y2 - y1)\n",
    "    aspect_ratio = (x2 - x1) / (y2 - y1)\n",
    "\n",
    "    return np.array([center_x, center_y, scale, aspect_ratio]).reshape((4, 1))\n",
    "\n",
    "def convert_x_to_bbox(z):\n",
    "    center_x, center_y, scale, aspect_ratio = z\n",
    "    width = math.sqrt(scale * aspect_ratio)\n",
    "    height = math.sqrt(scale / aspect_ratio)\n",
    "    x1 = center_x - width / 2\n",
    "    y1 = center_y - height / 2\n",
    "    x2 = center_x + width / 2\n",
    "    y2 = center_y + height / 2\n",
    "\n",
    "    return np.array([x1, y1, x2, y2]).reshape((1,4))\n",
    "\n",
    "class KalmanBoxTracker(object):\n",
    "    def __init__(self,bbox):\n",
    "        self.idx = bbox[4]\n",
    "        bbox = bbox[:4]\n",
    "        \n",
    "        #define constant velocity model\n",
    "        self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "        self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "        self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "        self.kf.R[2:,2:] *= 10.\n",
    "        self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "        self.kf.P *= 10.\n",
    "        self.kf.Q[-1,-1] *= 0.01\n",
    "        self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "        self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "\n",
    "    def update(self,bbox):\n",
    "        self.kf.update(convert_bbox_to_z(bbox[:4]))\n",
    "\n",
    "    def predict(self):\n",
    "        self.kf.predict()\n",
    "        return convert_x_to_bbox(self.kf.x[:4])\n",
    "\n",
    "    def get_state(self):\n",
    "        return convert_x_to_bbox(self.kf.x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f06fab77-676f-44dc-b7ff-fca4ccfa393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustSORT:\n",
    "    def __init__(self):\n",
    "        self.trackers = []\n",
    "        self.max_trackers_id = 0\n",
    "        \n",
    "    def update(self, detections):\n",
    "        if self.trackers == []:\n",
    "            track_bbs_ids, self.max_trackers_id = update_trackers([], detections, self.max_trackers_id)\n",
    "            track_bbs_ids = track_bbs_ids.cpu().numpy()\n",
    "            for matched_tracker in track_bbs_ids:\n",
    "                self.trackers.append(KalmanBoxTracker(matched_tracker))\n",
    "            return track_bbs_ids\n",
    "        \n",
    "        \n",
    "        bbs_trackers = []\n",
    "        for i in self.trackers:\n",
    "            bbox_coords = i.predict()[0]\n",
    "            bbox_idx = np.array([i.idx])\n",
    "            bbox_arr = np.concatenate([bbox_coords, bbox_idx])\n",
    "            bbs_trackers.append(bbox_arr)\n",
    "        bbs_trackers = torch.tensor(bbs_trackers).to(device).to(torch.float32)\n",
    "        \n",
    "        track_bbs_ids, max_trackers_id = update_trackers(bbs_trackers, detections, self.max_trackers_id)\n",
    "        track_bbs_ids = track_bbs_ids.cpu().numpy()\n",
    "        \n",
    "        new_trackers = []\n",
    "        for tracker in self.trackers:\n",
    "            for matched_tracker in track_bbs_ids:\n",
    "                if matched_tracker[4] == tracker.idx:\n",
    "                    tracker.update(matched_tracker[:4])\n",
    "                    new_trackers.append(tracker)\n",
    "        \n",
    "        # print(\"(track_bbs_ids[:, 4] > self.max_trackers_id).sum(): \", (track_bbs_ids[:, 4] > self.max_trackers_id).sum())\n",
    "        # print(\"track_bbs_ids[:, 4].max(): \", track_bbs_ids[:, 4].max())\n",
    "        counter = 0\n",
    "        for matched_tracker in track_bbs_ids:\n",
    "            if matched_tracker[4] > self.max_trackers_id:\n",
    "                counter += 1\n",
    "                # print(matched_tracker[4], self.max_trackers_id)\n",
    "                new_trackers.append(KalmanBoxTracker(matched_tracker))\n",
    "        \n",
    "        self.max_trackers_id = max_trackers_id\n",
    "                \n",
    "        # print(\"self.max_trackers_id: \", self.max_trackers_id)\n",
    "        # print(\"counter: \", counter)\n",
    "        \n",
    "        self.trackers = new_trackers\n",
    "        \n",
    "        result_bboxes = []\n",
    "        for i in self.trackers:\n",
    "            bbox_coords = i.get_state()[0]\n",
    "            bbox_idx = np.array([i.idx])\n",
    "            bbox_arr = np.concatenate([bbox_coords, bbox_idx])\n",
    "            result_bboxes.append(bbox_arr)\n",
    "        \n",
    "        return np.array(result_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2744e7ca-8d60-437b-a56e-c7b1dfadfb91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                                 | 101/1050 [01:23<13:03,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "file = str(reference_vid)\n",
    "verbose = True\n",
    "\n",
    "capture = cv2.VideoCapture(file)\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "n_frames = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "bbs_ids_frame_count = {}\n",
    "\n",
    "frames = []\n",
    "\n",
    "sort = CustSORT()\n",
    "\n",
    "pb = np.arange(n_frames)\n",
    "if verbose:\n",
    "    pb = tqdm(pb)\n",
    "    \n",
    "def generate_noise(detections):\n",
    "    noise = (torch.randn(detections.shape) * 50).to(device)\n",
    "    noise[noise < 0] *= -1.\n",
    "    return noise\n",
    "\n",
    "for i in pb:\n",
    "    success, image_cv = capture.read()\n",
    "    # if i > 100: break # TODO: remove this line\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    preds = model(image_cv)\n",
    "    detections = preds.pred[0][..., :4]\n",
    "    detections = detections# + generate_noise(detections)\n",
    "    track_bbs_ids = sort.update(detections)\n",
    "    \n",
    "    for j in range(len(track_bbs_ids)):\n",
    "        coords = track_bbs_ids[j]\n",
    "        x1, y1, x2, y2 = int(coords[0]), int(coords[1]), int(coords[2]), int(coords[3])\n",
    "        \n",
    "        name_idx = int(coords[4])\n",
    "        \n",
    "        if name_idx in bbs_ids_frame_count.keys():\n",
    "            bbs_ids_frame_count[name_idx] += 1\n",
    "        else:\n",
    "            bbs_ids_frame_count[name_idx] = 1\n",
    "            \n",
    "        sec_per_id = bbs_ids_frame_count[name_idx] / fps\n",
    "            \n",
    "        name = f\"ID:{name_idx}|T:{sec_per_id:.2f}s\"\n",
    "        color = color_t(name_idx)\n",
    "        \n",
    "        cv2.rectangle(image_cv, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image_cv, name, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        cv2.imwrite(str(save_to / f\"{int(i)}.png\"), image_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f7808-fa45-4817-8c4d-68802f0b2d32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Kalman filter on one bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5bca1e58-7abb-44c1-82df-f32c9b961d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                             | 396/1050 [00:30<00:50, 13.08it/s]\n"
     ]
    }
   ],
   "source": [
    "file = str(reference_vid)\n",
    "verbose = True\n",
    "\n",
    "capture = cv2.VideoCapture(file)\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "n_frames = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "bbs_ids_frame_count = {}\n",
    "\n",
    "frames = []\n",
    "\n",
    "track_bbs_ids = []\n",
    "max_trackers_id = 0\n",
    "\n",
    "pb = np.arange(n_frames)\n",
    "if verbose:\n",
    "    pb = tqdm(pb)\n",
    "    \n",
    "kf = None\n",
    "\n",
    "for i in pb:\n",
    "    success, image_cv = capture.read()\n",
    "    if i > 395: break # TODO: remove this line\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    preds = model(image_cv)\n",
    "    detections = preds.pred[0][..., :4]\n",
    "    track_bbs_ids, max_trackers_id = update_trackers(track_bbs_ids, detections, max_trackers_id)\n",
    "    \n",
    "    raw_coords = track_bbs_ids[track_bbs_ids[:, 4] == 4.][0].cpu().numpy()\n",
    "    \n",
    "    coords = track_bbs_ids[track_bbs_ids[:, 4] == 4.][0].cpu().numpy()\n",
    "    \n",
    "    name_idx = int(coords[4])\n",
    "    \n",
    "    if kf == None:\n",
    "        kf = KalmanBoxTracker(coords)\n",
    "    kf.predict()[0]\n",
    "    \n",
    "    kf.update(coords)\n",
    "    \n",
    "    coords = kf.get_state()[0]\n",
    "    \n",
    "    x1, y1, x2, y2 = int(coords[0]), int(coords[1]), int(coords[2]), int(coords[3])\n",
    "\n",
    "    if name_idx in bbs_ids_frame_count.keys():\n",
    "        bbs_ids_frame_count[name_idx] += 1\n",
    "    else:\n",
    "        bbs_ids_frame_count[name_idx] = 1\n",
    "\n",
    "    sec_per_id = bbs_ids_frame_count[name_idx] / fps\n",
    "\n",
    "    name = f\"ID:{name_idx}|T:{sec_per_id:.2f}s\"\n",
    "    color = color_t(name_idx)\n",
    "    color_raw = color_t(name_idx+1)\n",
    "\n",
    "    cv2.rectangle(image_cv, (int(raw_coords[0]), int(raw_coords[1])), (int(raw_coords[2]), int(raw_coords[3])), color_raw, 2)\n",
    "    cv2.putText(image_cv, name, (int(raw_coords[0]), int(raw_coords[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color_raw, 2)\n",
    "    \n",
    "    cv2.rectangle(image_cv, (x1, y1), (x2, y2), color, 2)\n",
    "    cv2.putText(image_cv, name, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "    \n",
    "    cv2.imwrite(str(save_to / f\"{int(i)}.png\"), image_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cba04d5-9bb1-463d-baf9-0c94ec0916f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521.86285"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06059328-5327-4d31-92fa-9f2fcc365536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     521.86,      64.777,      555.21,      156.76,           4], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf368c71-4d7b-4160-b45b-5ee1f7c145e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([521.86285,  64.77745, 555.20526, 156.76003,   4.00000], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e3ed8-fc29-4b17-95dc-8a666dcdc4d3",
   "metadata": {},
   "source": [
    "# Save video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "438ab9e0-4783-44c1-8c3e-1769ef4689df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in /opt/conda/lib/python3.8/site-packages (1.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install moviepy --upgrade\n",
    "# !pip install ffmpeg --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "550bb5c7-aa16-4a90-8e7e-181f75bed231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:01<00:00, 58.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = str(save_to)\n",
    "video_name = 'video_hungarian.mp4'\n",
    "fps = 30\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "sorted_img_ids = sorted([int(i.split('.')[0]) for i in images])\n",
    "images = [f\"{i}.png\" for i in sorted_img_ids]\n",
    "\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "video = cv2.VideoWriter(video_name, fourcc, fps, (width,height))\n",
    "\n",
    "for image in tqdm(images):\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
